{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ChennaiHacks.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import Libraries"
      ],
      "metadata": {
        "id": "PvEMCwLkaTrm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wv0PDy8WaT2U"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from numpy import loadtxt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the dataset\n"
      ],
      "metadata": {
        "id": "7moEwAHMcUe_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1x9ztpUDKnL1XQFnpvPfIip52KpmFs-Me"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8OGoLfubCmM",
        "outputId": "ed9a1699-28b6-4661-a0b4-6ba291594635"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1x9ztpUDKnL1XQFnpvPfIip52KpmFs-Me\n",
            "To: /content/clean_profile_data_all.csv\n",
            "100% 628k/628k [00:00<00:00, 4.74MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('clean_profile_data_all.csv')"
      ],
      "metadata": {
        "id": "37x55Cm3aaLA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "iIqMFgNXnKM2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name=[]\n",
        "model_train_acc=[]\n",
        "model_test_accuracy=[]\n",
        "model_train_f1=[]\n",
        "model_test_f1=[]\n",
        "def get_result(model, X_train, X_test, Y_train, Y_test):\n",
        "    sc = StandardScaler() \n",
        "    sc.fit(X_train)\n",
        "    X_train = sc.transform(X_train)\n",
        "    X_test = sc.transform(X_test) \n",
        "    model.fit(X_train, Y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    prob_test=pd.DataFrame(model.predict_proba(X_test))\n",
        "    prob_train=pd.DataFrame(model.predict_proba(X_train))\n",
        "    test_f1_score = f1_score(Y_test, y_pred,pos_label='accept')\n",
        "    train_f1_score = f1_score(Y_train, y_train_pred,pos_label='accept')\n",
        "    train_accuracy=accuracy_score(Y_train, y_train_pred)\n",
        "    test_accuracy=accuracy_score(Y_test, y_pred)\n",
        "    test_cm = confusion_matrix(Y_test, y_pred,labels=['accept','reject'])\n",
        "    train_cm = confusion_matrix(Y_train, y_train_pred,labels=['accept','reject'])\n",
        "    model_name.append(model)\n",
        "    model_train_acc.append(train_accuracy)\n",
        "    model_test_accuracy.append(test_accuracy)\n",
        "    model_test_f1.append(test_f1_score)\n",
        "    model_train_f1.append(train_f1_score)\n",
        "    return [train_cm,test_cm,train_accuracy,test_accuracy,train_f1_score, test_f1_score, prob_train,prob_test, y_pred,y_train_pred, model,sc]"
      ],
      "metadata": {
        "id": "6VBPLYCZnVQY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_university=[\"northeastern_university\",\"clemson_university\",\"george_mason_university\",\"georgia_institiute_of_technology\",\"illinois_institute_of_technology\",\"kansas_state_university\",\"north_carolina_state_university_raleigh\",\"new_york_university\",\"rochester_institute_of_technology\",\"rutgers_university_new_brunswick\",\"state_university_of_new_york_at_stony_brook\",\"syracuse_university\",\"texas_a_m_university_college_station\",\"university_of_connecticut\",\"university_of_colorado_boulder\",\"university_of_florida\",\"university_of_north_carolina_at_charlotte\",\n",
        "\n",
        "\"university_of_texas_arlington\",\n",
        "\"university_of_texas_dallas\",\n",
        "\"worcester_polytechnic_institute\"]"
      ],
      "metadata": {
        "id": "DWKhu9PwnY7B"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix\n",
        "import pickle\n",
        "import math\n",
        "acc=[]\n",
        "for university in selected_university:\n",
        "    data = dataset[(dataset.university_name == university)]\n",
        "    training, testing = train_test_split(data, test_size=0.25, random_state=5, stratify=data['status'])\n",
        "    numerical_data = training.select_dtypes(include = ['int64','float','uint8'])\n",
        "    categorical_data = training.select_dtypes(include = ['object'])\n",
        "    categorical_features = categorical_data.columns.values\n",
        "    numerical_features = numerical_data.columns.values\n",
        "    numerical_features = numerical_data.columns.values[:-1]\n",
        "    random_forest_model=RandomForestClassifier(n_estimators=10)\n",
        "    randomforest_model_results=get_result(random_forest_model,training[numerical_features],testing[numerical_features],training['status'],testing['status'])\n",
        "    print(university+' test_accuracy:',randomforest_model_results[3])\n",
        "    acc.append(randomforest_model_results[3])\n",
        "    # print('train_accuracy:',randomforest_model_results[2])\n",
        "    # print('test_f1_score:',randomforest_model_results[5])\n",
        "    # print('train_f1_score:',randomforest_model_results[4])\n",
        "    # generate_cm_roc(randomforest_model_results)  \n",
        "    rf_classifier_pkl_filename = university+'.pickel'\n",
        "    random_forest_classifier_model_pkl = open(rf_classifier_pkl_filename, 'wb')\n",
        "    pickle.dump(randomforest_model_results[10], random_forest_classifier_model_pkl)\n",
        "    random_forest_classifier_model_pkl.close()\n",
        "    # print(training.head())\n",
        "print(sum(acc)/len(acc))"
      ],
      "metadata": {
        "id": "w-jzMTFZnCde",
        "outputId": "13e34e2a-77d8-43fc-f407-cbefec1f5688",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "northeastern_university test_accuracy: 0.6763285024154589\n",
            "clemson_university test_accuracy: 0.8387096774193549\n",
            "george_mason_university test_accuracy: 0.7424242424242424\n",
            "georgia_institiute_of_technology test_accuracy: 0.71875\n",
            "illinois_institute_of_technology test_accuracy: 0.6513761467889908\n",
            "kansas_state_university test_accuracy: 0.5789473684210527\n",
            "north_carolina_state_university_raleigh test_accuracy: 0.782312925170068\n",
            "new_york_university test_accuracy: 0.525\n",
            "rochester_institute_of_technology test_accuracy: 0.7325581395348837\n",
            "rutgers_university_new_brunswick test_accuracy: 0.6447368421052632\n",
            "state_university_of_new_york_at_stony_brook test_accuracy: 0.5894039735099338\n",
            "syracuse_university test_accuracy: 0.6230769230769231\n",
            "texas_a_m_university_college_station test_accuracy: 0.7216494845360825\n",
            "university_of_connecticut test_accuracy: 0.75\n",
            "university_of_colorado_boulder test_accuracy: 0.813953488372093\n",
            "university_of_florida test_accuracy: 0.7083333333333334\n",
            "university_of_north_carolina_at_charlotte test_accuracy: 0.6105263157894737\n",
            "university_of_texas_arlington test_accuracy: 0.6538461538461539\n",
            "university_of_texas_dallas test_accuracy: 0.8403361344537815\n",
            "worcester_polytechnic_institute test_accuracy: 0.6666666666666666\n",
            "0.6934468158931877\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import joblib\n",
        "for university in selected_university:\n",
        "  loaded_model = joblib.load( \"./\"+university+\".pickel\")\n",
        "  print(university+\" \"+loaded_model.predict([[0.0, 0.0,  0.0,0.0,0.0,0.0,0.0]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3n1SQKnPtXRn",
        "outputId": "34c24863-de65-4fe7-ca48-4ba4822a75c3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['northeastern_university reject']\n",
            "['clemson_university accept']\n",
            "['george_mason_university accept']\n",
            "['georgia_institiute_of_technology accept']\n",
            "['illinois_institute_of_technology accept']\n",
            "['kansas_state_university accept']\n",
            "['north_carolina_state_university_raleigh reject']\n",
            "['new_york_university reject']\n",
            "['rochester_institute_of_technology accept']\n",
            "['rutgers_university_new_brunswick reject']\n",
            "['state_university_of_new_york_at_stony_brook accept']\n",
            "['syracuse_university accept']\n",
            "['texas_a_m_university_college_station reject']\n",
            "['university_of_connecticut accept']\n",
            "['university_of_colorado_boulder reject']\n",
            "['university_of_florida accept']\n",
            "['university_of_north_carolina_at_charlotte reject']\n",
            "['university_of_texas_arlington accept']\n",
            "['university_of_texas_dallas accept']\n",
            "['worcester_polytechnic_institute accept']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "university = ['northeastern_university', 'carnegie_mellon_university',\n",
        "       'clemson_university', 'george_mason_university',\n",
        "       'georgia_institiute_of_technology',\n",
        "       'illinois_institute_of_technology',\n",
        "       'indiana_university_bloomington', 'kansas_state_university',\n",
        "       'university_of_maryland_college_park',\n",
        "       'michigan_technological_university',\n",
        "       'north_carolina_state_university_raleigh', 'new_york_university',\n",
        "       'rochester_institute_of_technology',\n",
        "       'rutgers_university_new_brunswick',\n",
        "       'state_university_of_new_york_at_stony_brook',\n",
        "       'syracuse_university', 'texas_a_m_university_college_station',\n",
        "       'university_of_connecticut', 'university_of_colorado_boulder',\n",
        "       'university_of_california_irvine', 'university_of_florida',\n",
        "       'university_of_north_carolina_at_charlotte',\n",
        "       'university_of_southern_california',\n",
        "       'university_of_texas_arlington', 'university_of_texas_austin',\n",
        "       'university_of_texas_dallas', 'university_of_iowa',\n",
        "       'university_of_cincinnati', 'worcester_polytechnic_institute']\n",
        "import joblib\n",
        "for university in selected_university:\n",
        "  loaded_model = joblib.load( \"/content/Machine-Learning-Graduate-Studuent-Admission-Predictor/Final Project _ Graduate Admission Predictor/Data/\"+university+\".pickel\")\n",
        "  print(university+\" \"+loaded_model.predict([[0.0, 0.0,  0.0,0.0,0.0,0.0,0.0]]))"
      ],
      "metadata": {
        "id": "t8nmCNeI5PC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.university_name.unique()\n",
        "\n"
      ],
      "metadata": {
        "id": "hgucdLCE5PHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZF9unmVKmxxi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ebXNaXMOew6h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def trainmodel(X_train,y_train,X_test,y_test):\n",
        "  import keras\n",
        "  from keras.models import Sequential\n",
        "  from keras.layers import Dense# Neural network\n",
        "  model = Sequential()\n",
        "  model.add(Dense(16, input_dim=20, activation='relu'))\n",
        "  model.add(Dense(12, activation='relu'))\n",
        "  model.add(Dense(4, activation='softmax'))\n",
        "  #Dependencies\n",
        "  import keras\n",
        "  from keras.models import Sequential\n",
        "  from keras.layers import Dense# Neural network\n",
        "  model = Sequential()\n",
        "  model.add(Dense(16, input_dim=7, activation='relu'))\n",
        "  model.add(Dense(12, activation='relu'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  history = model.fit(X_train, y_train, epochs=100, batch_size=64)\n",
        "  y_pred = model.predict(X_test)\n",
        "  #Converting predictions to label\n",
        "  pred = list()\n",
        "  for i in range(len(y_pred)):\n",
        "      pred.append(np.argmax(y_pred[i]))\n",
        "  #Converting one hot encoded test label to label\n",
        "  test = list()\n",
        "  for i in range(len(y_test)):\n",
        "      test.append(np.argmax(y_test[i]))"
      ],
      "metadata": {
        "id": "RL4d07ABWHFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_x_train=[]\n",
        "dataset_x_test=[]\n",
        "dataset_y_train=[]\n",
        "dataset_y_test=[]\n",
        "\n",
        "for university in selected_university:\n",
        "    data = dataset[(dataset.university_name == university)]\n",
        "    training, testing = train_test_split(data, test_size=0.25, random_state=5, stratify=data['status'])\n",
        "    numerical_data = training.select_dtypes(include = ['int64','float','uint8'])\n",
        "    categorical_data = training.select_dtypes(include = ['object'])\n",
        "    categorical_features = categorical_data.columns.values\n",
        "    numerical_features = numerical_data.columns.values\n",
        "    numerical_features = numerical_data.columns.values[:-1]\n",
        "    random_forest_model=RandomForestClassifier(n_estimators=10)\n",
        "    result = training['status'].replace('reject', 0)\n",
        "    result=result .replace('accept',1)    \n",
        "    result_test=testing['status'].replace('reject',0)\n",
        "    result_test=result_test.replace('accept',1)\n",
        "    # trainmodel(training[numerical_features],result,testing[numerical_features],result_test)\n",
        "    X_train=training[numerical_features]\n",
        "    y_train=result\n",
        "    X_test=testing[numerical_features]\n",
        "    y_test=result_test\n",
        "    dataset_x_train.append(X_train)\n",
        "    dataset_x_test.append(X_test)\n",
        "    dataset_y_train.append(y_train)\n",
        "    dataset_y_test.append(y_test)\n",
        "\n",
        "\n",
        "\n",
        "    import keras\n",
        "    from keras.models import Sequential\n",
        "    from keras.layers import Dense# Neural network\n",
        "    model = Sequential()\n",
        "    model.add(Dense(7, input_dim=7, activation='relu'))\n",
        "    model.add(Dense(64,activation=\"relu\"))\n",
        "    model.add(Dense(48,activation=\"relu\"))\n",
        "    model.add(Dense(24,activation=\"relu\"))\n",
        "    model.add(Dense(16,activation=\"relu\"))\n",
        "    model.add(Dense(8,activation=\"relu\"))\n",
        "    model.add(Dense(8,activation=\"relu\"))\n",
        "    model.add(Dense(8,activation=\"relu\"))\n",
        "    model.add(Dense(8,activation=\"relu\"))\n",
        "    model.add(Dense(8,activation=\"relu\"))\n",
        "    model.add(Dense(4,activation=\"relu\"))\n",
        "    model.add(Dense(2,activation=\"relu\"))\n",
        "    # model.add(Dense(8, activation='relu'))\n",
        "    # model.add(Dense(6, activation='relu'))\n",
        "    # model.add(Dense(5, activation='relu'))\n",
        "    # model.add(Dense(4, activation='relu'))\n",
        "    # model.add(Dense(3, activation='relu'))\n",
        "    # model.add(Dense(2, activation='relu'))\n",
        "    # model.add(Dense(12, activation='relu'))\n",
        "    # model.add(Dense(12, activation='relu'))\n",
        "\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    history = model.fit(X_train, y_train, validation_data=(X_test,y_test),epochs=50, batch_size=64,verbose=1)\n",
        "    y_pred = model.predict(X_test)\n",
        "    #Converting predictions to label\n",
        "    pred = list()\n",
        "    for i in range(len(y_pred)):\n",
        "        pred.append(0 if i<0.50 else 1)\n",
        "    #Converting one hot encoded test label to label\n",
        "    test = list()\n",
        "    # for i in range(len(y_test)):\n",
        "    #     test.append(np.argmax(y_test[i]))\n",
        "    score, acc = model.evaluate(X_test, y_test,\n",
        "                            batch_size=5)\n",
        "    print('Test score:', score)\n",
        "    print('Test accuracy:', acc)\n",
        "    score, acc = model.evaluate(X_train, y_train,\n",
        "                            batch_size=5)\n",
        "    print('Train score:', score)\n",
        "    print('Train accuracy:', acc)\n",
        "    model.save(university+\"_model.h5\")\n",
        "    from keras.models import load_model\n",
        "    model = load_model(university+\"_model.h5\")\n",
        "    print(\"pred\",model.predict(X_test[:1]))\n",
        "    # randomforest_model_results=get_result(random_forest_model,training[numerical_features],testing[numerical_features],training['status'],testing['status'])\n",
        "    print(university+' test_accuracy:',randomforest_model_results[3])\n",
        "    # print('train_accuracy:',randomforest_model_results[2])\n",
        "    # print('test_f1_score:',randomforest_model_results[5])\n",
        "    # print('train_f1_score:',randomforest_model_results[4])\n",
        "    # generate_cm_roc(randomforest_model_results)  \n",
        "    rf_classifier_pkl_filename = university+'.pickel'\n",
        "    random_forest_classifier_model_pkl = open(rf_classifier_pkl_filename, 'wb')\n",
        "    pickle.dump(randomforest_model_results[10], random_forest_classifier_model_pkl)\n",
        "    random_forest_classifier_model_pkl.close()\n",
        "    # print(training.head())\n",
        "    break"
      ],
      "metadata": {
        "id": "rcG2WzT9WroG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_x_train=[]\n",
        "dataset_x_test=[]\n",
        "dataset_y_train=[]\n",
        "dataset_y_test=[]\n",
        "\n",
        "for university in selected_university:\n",
        "    data = dataset[(dataset.university_name == university)]\n",
        "    training, testing = train_test_split(data, test_size=0.25, random_state=5, stratify=data['status'])\n",
        "    numerical_data = training.select_dtypes(include = ['int64','float','uint8'])\n",
        "    categorical_data = training.select_dtypes(include = ['object'])\n",
        "    categorical_features = categorical_data.columns.values\n",
        "    numerical_features = numerical_data.columns.values\n",
        "    numerical_features = numerical_data.columns.values[:-1]\n",
        "    random_forest_model=RandomForestClassifier(n_estimators=10)\n",
        "    result = training['status'].replace('reject', 0)\n",
        "    result=result .replace('accept',1)    \n",
        "    result_test=testing['status'].replace('reject',0)\n",
        "    result_test=result_test.replace('accept',1)\n",
        "    # trainmodel(training[numerical_features],result,testing[numerical_features],result_test)\n",
        "    X_train=training[numerical_features]\n",
        "    y_train=result\n",
        "    X_test=testing[numerical_features]\n",
        "    y_test=result_test\n",
        "    dataset_x_train.append(X_train)\n",
        "    dataset_x_test.append(X_test)\n",
        "    dataset_y_train.append(y_train)\n",
        "    dataset_y_test.append(y_test)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rMUKFkZ0zTEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# for university in dataset.university_name.unique():\n",
        "#     data = dataset[(dataset.university_name == university)]\n",
        "#     training, testing = train_test_split(data, test_size=0.25, random_state=5, stratify=data['status'])\n",
        "#     numerical_data = training.select_dtypes(include = ['int64','float','uint8'])\n",
        "#     categorical_data = training.select_dtypes(include = ['object'])\n",
        "#     categorical_features = categorical_data.columns.values\n",
        "#     numerical_features = numerical_data.columns.values\n",
        "#     numerical_features = numerical_data.columns.values[:-1]\n",
        "#     result = training['status'].replace('reject', 0)\n",
        "#     result=result .replace('accept',1)    \n",
        "#     result_test=testing['status'].replace('reject',0)\n",
        "#     result_test=result_test.replace('accept',1)\n",
        "#     datastat(result_test,university)\n",
        "# selected_university=[\"northeastern_university\",\"clemson_university\",\"george_mason_university\",\"georgia_institiute_of_technology\",\"illinois_institute_of_technology\",\"kansas_state_university\",\"north_carolina_state_university_raleigh\",\"new_york_university\",\"rochester_institute_of_technology\",\"rutgers_university_new_brunswick\",\"state_university_of_new_york_at_stony_brook\",\"syracuse_university\",\"texas_a_m_university_college_station\",\"university_of_connecticut\",\"university_of_colorado_boulder\",\"university_of_florida\",\"university_of_north_carolina_at_charlotte\",\n",
        "\n",
        "# \"university_of_texas_arlington\",\n",
        "# \"university_of_texas_dallas\",\n",
        "# \"worcester_polytechnic_institute\"]"
      ],
      "metadata": {
        "id": "wtjZX_u-nLip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_university\n"
      ],
      "metadata": {
        "id": "JLVXUdootnW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training[:1]"
      ],
      "metadata": {
        "id": "fe0Ac6HbGCbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for university in selected_university:\n",
        "    data = dataset[(dataset.university_name == university)]\n",
        "    data = data[(data.status == \"accept\")]\n",
        "    print(university+\" \"+str(sum(data[\"test_score_toefl\"])/len(data[\"test_score_toefl\"])))"
      ],
      "metadata": {
        "id": "XNI6_Cm3uDTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iCt4bplAvaDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def datastat(result_test,university):\n",
        "  tr=0\n",
        "  fa=0\n",
        "  for i in result_test:\n",
        "    if(i==0):\n",
        "      fa=fa+1\n",
        "    else:\n",
        "      tr=tr+1\n",
        "\n",
        "  if((tr)/(len(result_test))>0.30  and (fa)/(len(result_test)) >0.30):\n",
        "      print(university)\n",
        "      print(\"SIze \"+str(len(result_test)))\n",
        "      print(\"True \"+str((tr)/(len(result_test))) +\" %\")\n",
        "      print(\"False\"+str((fa)/(len(result_test))) + \" %\")\n"
      ],
      "metadata": {
        "id": "FcoSRNGRctX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(training['status'])\n",
        "result = training['status'].replace('reject', 0)\n",
        "result .replace('accept',1)"
      ],
      "metadata": {
        "id": "SXXIaMbVaFek"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}